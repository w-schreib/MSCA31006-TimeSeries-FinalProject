---
title: "MSCA 31006 Time Series - Final Project - EDA (WIP)"
author: "Whitney Schreiber"
date: '2022-05-08'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# load packages
suppressPackageStartupMessages({
  library(dplyr)
  library(zoo)
  library(xts)
  library(tseries)
  library(forecast)
  library(TSA)
  library(reshape2)
  library(naniar)
})
```

## Import data

Daily temperature of major cities data downloaded from:
https://www.kaggle.com/datasets/sudalairajkumar/daily-temperature-of-major-cities?resource=download

Data set includes the daily average temperature between 1995-2020 for 
321 different cities in 125 different countries in 7 different regions

Variables:

- `Region`
- `Country`
- `State` (note: corresponds to US/US territories, blank otherwise)
- `City`
- `Month`
- `Day`
- `Year`
- `AvgTemperature`

```{r}
raw_df <- read.csv("city_temperature.csv")
head(raw_df)
```

## Data structure and transformations

```{r}
# unique values
lapply(raw_df %>% dplyr::select(-c("AvgTemperature")),unique)
# length of unique values
lapply(
  lapply(raw_df %>% dplyr::select(-c("AvgTemperature")),unique), 
  length)
```

Explore unusual `Day` and `Year` values

- `Day` 0
- `Year` 200
- `Year` 201

```{r}
# raw_df[which(raw_df$Day==0 | raw_df$Year==200 | raw_df$Year==201),]
raw_df[which(raw_df$Day==0 | raw_df$Year==200 | raw_df$Year==201),"Country"] %>% 
  unique()
```

The data set does not contain any unusual day/year values for America, 
so these unusual instances will be removed and no further investigation is needed.

# Subset US cities

```{r}
# filter for 'US', excluding 'US territories' 
dfUS.wip <- raw_df %>% dplyr::filter((Country=="US") & 
                                     (State!="Additional Territories"))
# combine `City` and `State`, structured as 'City, State'
dfUS.wip$City <- paste(dfUS.wip$City, dfUS.wip$State, sep=", ")
# unique values
lapply(dfUS.wip %>% dplyr::select(-c("AvgTemperature")), unique)
# length of unique values
lapply(
  lapply(dfUS.wip %>% dplyr::select(-c("AvgTemperature")), unique), 
  length)
# drop Region, Country, and State (columns are now redundant)
dfUS.wip <- dfUS.wip %>% select(-c("Region", "Country", "State"))
# check for null values
dfUS.wip[is.na(dfUS.wip)]
```

**Create `Date` field**

```{r}
dfUS.wip <- dfUS.wip %>%
  mutate(Date = as.Date(with(dfUS.wip,paste(Year,Month,Day,sep="-")),
                        "%Y-%m-%d")) %>%
  select(-c("Month","Day","Year"))
# number of days between the start and end date (inclusive)
n_days <- max(dfUS.wip$Date)-min(dfUS.wip$Date)+1
# confirm all (unique) dates are included
dfUS.wip$Date %>% unique() %>% length() == n_days
# print date range and n_days
cbind("start date"=min(dfUS.wip$Date),
      "end date"=max(dfUS.wip$Date),
      "number of days"=n_days)
```

### Check dates and cities

 1) all dates included for all cities
 2) no repeated dates in cities

```{r}
# number of records per day in the US
dateCountUS <- dfUS.wip %>% dplyr::count(Date)
# unique values
dateCountUS$n %>% unique() %>% sort()
```

Each date does not include a record for every city in the US. 
Determine which cities are missing days.

```{r}
# number of records in each city
cityCountUS <- dfUS.wip %>% dplyr::count(City)
# cities with incomplete date range dates 
(incompleteCityUS <- cityCountUS %>% dplyr::filter(cityCountUS$n != n_days))
```

Washington DC, Maryland and Washington, District of Columbia appear to have 
twice the number of records as days. Remove exact duplicates. 
Check whether the data for "Washington DC, Maryland" and 
"Washington, District of Columbia" are the same.

```{r}
# Remove duplicate values
dfUS.wip <- dfUS.wip %>% distinct()
```

```{r}
all(dfUS.wip[which(dfUS.wip$City=="Washington DC, Maryland"),"AvgTemperature"] ==
    dfUS.wip[which(dfUS.wip$City=="Washington, District of Columbia"),"AvgTemperature"])
```

Remove records for Washington DC, Maryland

```{r}
dfUS.wip <- dfUS.wip %>% dplyr::filter(City!="Washington DC, Maryland")
```

The new count of records for Washington, District of Columbia is correct

```{r}
dfUS.wip %>% 
  dplyr::filter(City=="Washington, District of Columbia") %>% 
  dplyr::count(City)
```

Check the ***new*** number of records in each city.

```{r}
cityCountUS <- dfUS.wip %>% dplyr::count(City)
(incompleteCityUS <- cityCountUS %>% dplyr::filter(cityCountUS$n != n_days))
```

Remove the 8 remaining US cities that have an incorrect number of records 
(our analysis will focus on a city with complete records). 

- Most of these cities are missing a substantial number of days (nearly 50%).
- Abilene, Texas has an additional record that is not an exact duplicate

```{r}
# remove cities with incomplete data
dfUS.wip <- dfUS.wip %>% dplyr::filter(!(City %in% incompleteCityUS$City))
```

Confirm that the number of records per day matches the number of cities

```{r}
# re-check number of records per day in the US
dateCountUS <- dfUS.wip %>% dplyr::count(Date)
dateCountUS$n %>% unique() == dfUS.wip$City %>% unique() %>% length()
```

```{r}
# confirm that the number of days in the data set has not changed 
dfUS.wip$Date %>% unique() %>% length() == n_days
```

### Summary statistics of `AvgTemperature` in US

```{r}
summary(dfUS.wip$AvgTemperature)
```

The minimum average temperature is -99, this is a placeholder for missing data.
After reshaping the data set, these instances will need to be adjusted.

```{r}
# number of records with AvgTemperature "-99" by date
dailycount99 <- dfUS.wip[which(dfUS.wip$AvgTemperature==-99),] %>% 
  dplyr::count(Date)
# left join the complete dates and the "-99" counts
dfdailycount99 <- dfUS.wip %>% select(Date) %>% 
  left_join(dailycount99, by="Date")
# replace na with 0
dfdailycount99[is.na(dfdailycount99)] <- 0
# plot the number of "-99" records with a "-99" AvgTemperature each day
plot(dfdailycount99, type="l", 
     main="Number of Records per Day with Incorrect (missing) Avg Temperature")
```

Number of records missing ("-99") AvgTemperature in each city

```{r}
cityCount99 <- dfUS.wip[which(dfUS.wip$AvgTemperature==-99),] %>% 
  dplyr::count(City)
# calculate pct missing
cityCount99$nPct <- cityCount99$n / as.numeric(n_days)
summary(cityCount99)
```

Overall, the number of records with missing ("-99") AvgTemperature in each city is small.

### Reshape data set, one column per city

```{r}
df_melt <- melt(dfUS.wip, id.vars = c("Date","City"))
head(df_melt)
dfUS <- dcast(df_melt, Date ~ City)
head(dfUS)
```

### Update values where `AvgTemperature` = -99 by forward filling 

```{r}
# set values of -99 to NA
dfUS <- dfUS %>% naniar::replace_with_na_all(condition = ~.x == -99)
# forward fill
dfUS <- na.locf(na.locf(dfUS), fromLast = FALSE)
```

### ~~~ ADD ANY OTHER TRANSFORMATIONS ~~~

### Final US data frame

Select subset of US cities

```{r}
# colnames(dfUS)
df <- dfUS %>% select(c("Date",
                        "Chicago, Illinois",
                        "Anchorage, Alaska",
                        "Denver, Colorado",
                        "Indianapolis, Indiana",
                        "Kansas City, Missouri",
                        "Las Vegas, Nevada",
                        "Los Angeles, California",
                        "Miami Beach, Florida",
                        "Minneapolis St. Paul, Minnesota",
                        "New York City, New York",
                        "Phoenix, Arizona",
                        "Raleigh Durham, North Carolina",
                        "San Antonio, Texas"
                        )) %>% rename(
                          Chicago="Chicago, Illinois",
                          Anchorage="Anchorage, Alaska",
                          Denver="Denver, Colorado",
                          Indianapolis="Indianapolis, Indiana",
                          KansasCity="Kansas City, Missouri",
                          LasVegas="Las Vegas, Nevada",
                          LosAngeles="Los Angeles, California",
                          Miami="Miami Beach, Florida",
                          Minneapolis="Minneapolis St. Paul, Minnesota",
                          NewYorkCity="New York City, New York",
                          Phoenix="Phoenix, Arizona",
                          Raleigh="Raleigh Durham, North Carolina",
                          SanAntonio="San Antonio, Texas"
                        )

```

```{r}
# Create xts object
USts <- xts(df, order.by = df$Date)
```

## Data Exploration

```{r}
summary(df)
```


```{r}

```

```{r}
plot(df$Date, df$Chicago, type = "l",
     main = "Daily Avg Temperature in Chicago",
     ylab = "Daily Avg Temperature", xlab = "Date")
```

plot ts

distribution of avg temp
-across cities

## Qualitative Analaysis for Autocorrelation

## Quantitative Analaysis for Autocorrelation

correlation between cities
- cor matrix
- cor matrix w different lags

test train split
- do we do EDA on the entire data set or just the train ?

cross-validation for ts ?


